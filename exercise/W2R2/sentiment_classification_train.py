# -*- coding: utf-8 -*-
# coding: utf-8
# @Time        : 2025/9/24
# @Author      : liuboyuan
# @Description :
# BGE-m3æ–‡æœ¬åµŒå…¥ + é€»è¾‘å›å½’æƒ…æ„Ÿåˆ†ç±»
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import joblib
from sklearn.linear_model import LogisticRegression
# åªä¿ç•™å¿…è¦çš„å¯¼å…¥
import matplotlib.pyplot as plt
# seabornå·²åˆ é™¤ï¼Œåªä½¿ç”¨matplotlibè¿›è¡Œå¯è§†åŒ–
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC', 'SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

# --- 1. åˆ›å»ºç¤ºä¾‹æƒ…æ„Ÿæ•°æ®é›† ---
print("åˆ›å»ºç¤ºä¾‹æƒ…æ„Ÿæ•°æ®é›†...")

sample_data = {
    'æ–‡æœ¬': [
        # æ­£é¢æƒ…æ„Ÿ (label=1)
        "è¿™ä¸ªäº§å“çœŸçš„å¤ªæ£’äº†ï¼Œæˆ‘éå¸¸æ»¡æ„ï¼",
        "æœåŠ¡æ€åº¦å¾ˆå¥½ï¼Œå·¥ä½œäººå‘˜å¾ˆçƒ­æƒ…",
        "è´¨é‡è¶…å‡ºäº†æˆ‘çš„é¢„æœŸï¼Œå¼ºçƒˆæ¨è",
        "ä»Šå¤©å¿ƒæƒ…ç‰¹åˆ«å¥½ï¼Œé˜³å…‰æ˜åªš",
        "è¿™å®¶é¤å…çš„èœå“å‘³é“å¾ˆèµ",
        "åŒäº‹ä»¬éƒ½å¾ˆå‹å–„ï¼Œå·¥ä½œç¯å¢ƒå¾ˆæ£’",
        "è¿™æ¬¡æ—…è¡Œéå¸¸æ„‰å¿«ï¼Œé£æ™¯å¦‚ç”»",
        "å­©å­ä»¬ç©å¾—å¾ˆå¼€å¿ƒï¼Œæ´»åŠ¨ç»„ç»‡å¾—å¾ˆå¥½",
        "å­¦åˆ°äº†å¾ˆå¤šæ–°çŸ¥è¯†ï¼Œæ”¶è·æ»¡æ»¡",
        "æœ‹å‹çš„ç”Ÿæ—¥èšä¼šåŠå¾—å¾ˆæˆåŠŸ",
        "éå¸¸æ„Ÿè°¢å¤§å®¶çš„å¸®åŠ©å’Œæ”¯æŒ",
        "è¿™æ¬¡åˆä½œéå¸¸æˆåŠŸï¼ŒæœŸå¾…ä¸‹æ¬¡",
        "å›¢é˜Ÿåä½œæ•ˆæœå¾ˆå¥½ï¼Œç›®æ ‡è¾¾æˆäº†",
        "æ–°åŠŸèƒ½ä½¿ç”¨èµ·æ¥å¾ˆæ–¹ä¾¿",
        "å®¢æˆ·åé¦ˆéå¸¸ç§¯ææ­£é¢",

        # è´Ÿé¢æƒ…æ„Ÿ (label=0)
        "è¿™ä¸ªäº§å“è´¨é‡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·é’±",
        "æœåŠ¡æ€åº¦æ¶åŠ£ï¼Œè®©äººå¾ˆä¸èˆ’æœ",
        "ç­‰äº†å¾ˆä¹…éƒ½æ²¡æœ‰å¾—åˆ°å›å¤ï¼Œå¾ˆå¤±æœ›",
        "ä»Šå¤©é‡åˆ°äº†å¾ˆå¤šéº»çƒ¦äº‹ï¼Œå¿ƒæƒ…ç³Ÿç³•",
        "è¿™å®¶åº—çš„é£Ÿç‰©éš¾åƒï¼Œç¯å¢ƒä¹Ÿä¸å¥½",
        "å·¥ä½œå‹åŠ›å¤ªå¤§ï¼Œæ¯å¤©éƒ½å¾ˆç–²æƒ«",
        "å¤©æ°”å¤ªçƒ­äº†ï¼Œè®©äººçƒ¦èºä¸å®‰",
        "äº¤é€šå µå¡ä¸¥é‡ï¼Œæµªè´¹äº†å¾ˆå¤šæ—¶é—´",
        "è€ƒè¯•æˆç»©ä¸ç†æƒ³ï¼Œæ„Ÿåˆ°å¾ˆæ²®ä¸§",
        "è®¾å¤‡å‡ºç°æ•…éšœï¼Œå½±å“äº†æ­£å¸¸å·¥ä½œ",
        "ç³»ç»Ÿå“åº”é€Ÿåº¦å¤ªæ…¢ï¼Œéœ€è¦ä¼˜åŒ–",
        "è¿™ä¸ªé”™è¯¯ä¸€ç›´è§£å†³ä¸äº†ï¼Œå¾ˆå¤´ç–¼",
        "é¢„ç®—ä¸è¶³ï¼Œé¡¹ç›®å¯èƒ½è¦å»¶æœŸ",
        "æ²Ÿé€šæ•ˆç‡å¾ˆä½ï¼Œæµªè´¹æ—¶é—´",
        "æŠ€æœ¯æ–¹æ¡ˆå­˜åœ¨ä¸¥é‡ç¼ºé™·"
    ],
    'label': [
        # æ­£é¢=1 (15ä¸ª)
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        # è´Ÿé¢=0 (15ä¸ª)
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
    ]
}

df = pd.DataFrame(sample_data)
print(f"æ•°æ®é›†å¤§å°: {len(df)}")
print(f"æ ‡ç­¾åˆ†å¸ƒ:\n{df['label'].value_counts()}")
print("æ ‡ç­¾å«ä¹‰: 0=è´Ÿé¢, 1=æ­£é¢")

# --- 2. åŠ è½½BGE-m3æ¨¡å‹å¹¶æå–ç‰¹å¾ ---
print("\nåŠ è½½BGE-m3æ¨¡å‹...")
MODEL_NAME = "BAAI/bge-m3"
model = SentenceTransformer(MODEL_NAME)

print("æå–æ–‡æœ¬åµŒå…¥ç‰¹å¾...")
text_embeddings = model.encode(df['æ–‡æœ¬'].tolist(), show_progress_bar=True)
print(f"åµŒå…¥ç‰¹å¾å½¢çŠ¶: {text_embeddings.shape}")

# --- 3. ç›´æ¥è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹ ---
print("\nè®­ç»ƒäºŒåˆ†ç±»é€»è¾‘å›å½’æ¨¡å‹...")

X = text_embeddings
y = df['label']

# ç›´æ¥ç”¨æ‰€æœ‰æ•°æ®è®­ç»ƒï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X, y)

# å­˜å‚¨æ¨¡å‹åˆ°æœ¬åœ°æ–‡ä»¶
joblib.dump(model, 'sentiment_model.joblib')
print("Model saved to sentiment_model.joblib")


print("è®­ç»ƒå®Œæˆï¼")

# --- 4. æƒé‡åˆ†æ ---
print("\n=== æƒé‡åˆ†æ ===")

# è·å–é€»è¾‘å›å½’çš„æƒé‡çŸ©é˜µ
coefficients = model.coef_
print(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {coefficients.shape}")
print(f"ç‰¹å¾ç»´åº¦æ•°: {coefficients.shape[1]}")
print(f"ç±»åˆ«æ•°: {coefficients.shape[0]}")

# è®¡ç®—æ¯ä¸ªç»´åº¦çš„é‡è¦æ€§ï¼ˆæƒé‡ç»å¯¹å€¼ï¼‰
feature_importance = np.abs(coefficients[0])
print(f"ç‰¹å¾ç»´åº¦æ•°: {coefficients.shape[1]}")
print(f"æœ€é‡è¦ç»´åº¦é‡è¦æ€§: {np.max(feature_importance):.3f}")

# æ‰¾å‡ºTop 10æƒé‡è´¡çŒ®æœ€å¤§çš„ç»´åº¦ï¼ˆæŒ‰ç»å¯¹å€¼æ’åºï¼‰
top_10_indices = np.argsort(feature_importance)[-10:]
print(f"\nTop 10 æƒé‡è´¡çŒ®ç»´åº¦ï¼ˆæŒ‰ç»å¯¹å€¼æ’åºï¼‰:")
for i, idx in enumerate(reversed(top_10_indices)):
    actual_weight = coefficients[0][idx]
    print(f"  ç»´åº¦ {idx}: {actual_weight:.3f}")

# å¯è§†åŒ–Top 10é‡è¦ç»´åº¦çš„LRæƒé‡
top_10_indices = np.argsort(feature_importance)[-10:]

plt.figure(figsize=(12, 8))
weights_top10 = coefficients[0][top_10_indices]  # äºŒåˆ†ç±»åªæœ‰ä¸€ä¸ªæƒé‡å‘é‡

# ç»Ÿä¸€é¢œè‰²æ˜¾ç¤ºæƒé‡
plt.bar(range(len(top_10_indices)), weights_top10, color='steelblue', alpha=0.7)

plt.xlabel('Top 10 é‡è¦ç»´åº¦')
plt.ylabel('LRæƒé‡å€¼')
plt.title('Top 10é‡è¦ç»´åº¦çš„LRæƒé‡åˆ†å¸ƒ')
plt.xticks(range(len(top_10_indices)), [f'ç»´åº¦{idx}' for idx in top_10_indices])
plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nğŸ¨ æƒé‡å¯è§†åŒ–å®Œæˆï¼")
print("âœ… äºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æï¼ˆæ­£é¢ vs è´Ÿé¢ï¼‰è®­ç»ƒå®Œæˆ")